---
layout: post
title: /Notes/ Kafka
---

_Research into Kafka_

- Kafka helps us handle the continuous flow of data.
- Kafka is oriented around the idea of treating data as a continually evolving and ever-growing stream.
- Think of it as a distributed streaming platform: a system that lets you publish and subscribe to streams of data, store them, and process them
- The low latency nature of Kafka makes it applicable for the kind of core apps that directly power a business. Events in a business are happening all the time and the ability to react to them as they occur makes it much easier to build services that directly power the operation of the business, feed back into customer experiences, and so on.
- Similar to a messaging system in that it lets you publish (send) and subscribe to (receive) streams of data (messages)
    - Differences tho:
        1. It works as a modern distributed system that runs as a cluster and can scale via a central platform
        1. It's a true storage system built to store data for as long as you need
        1. Has a higher level of abstraction; while messaging systems just hand out messages, Kafka's stream processing capabilities let you compute derived streams and datasets dynamically off of your streams, with far less code

**Kafka parts**  
<ins>Messages and Batches:</ins>

- A message is an array of bytes to Kafka, so its data does not have a specific meaning or format to Kafka
- Messages can have keys (optional bits of metadata); keys are used when messages need to be written to partitions in a more controlled manner
- Messages are written into Kafka in batches
    - a batch is a collection of messages, all of which are being produced to the same topic and partition

<ins>Schemas:</ins>

- It's recommended that additional structure be imposed on the message content so it can be easily understood. JSON and XML are more simplistic systems, but many devs favor Apache Avro (serialization framework)
- Consistent data format is important for true decoupling of reading and writing messages

<ins>Topics and Partitions:</ins>

- Messages are categorized into topics
    - closest analogy for a topic is a directory or table
- Topics are broken down into partitions
- Messages are written to a partition in an append-only manner, are read in order from beginning to end
- If a topic has multiple partitions, there is no guarantee of message time-ordering across the topic; only within a single partition
- Partitions are how Kafka provides redundancy and scalability
    - each partition can be hosted on a different server, which means that a single topic can be scaled horizontally across multiple servers
- a stream is considered to be a single topic of data, regardless of the number of partitions

<ins>Producers and Consumers:</ins>

- Two basic types of Kafka clients (clients are users of the system)
- Producers create new messages. May also be referred to as publishers or writers.
- Consumers read messages. May also be referred to as subscribers or readers.
- How they work together:
    - By default, producer does not care what partition a specific message is written to and will balance messages over all partitions of a topic evenly.
    - In some cases, the producer will direct messages to specific partitions, assuring that all messages produced with a given key will get written to the same partition
    - Consumer subscribes to one or more topics and reads the messages in the order in which they were produced.
    - Consumer keeps track of which messages it has already consumed by keeping track of the offset of messages
        - the offset is another bit of metadata that Kafka adds to each message as it's produced. It's an integer value that continually increases.
        - By storing the offset of the last consumed message for each partition, a consumer can stop and restart without losing its place
    - Consumers work as part of a consumer group to consume a topic. The group assures that each partition is only consumed by one member.
        - The mapping of a consumer to a partition is often called ownership of the partition by the consumer
    - Consumers can thus horizontally scale to consume topics with a large number of messages. 
    - If a single consumer fails, remaining members of the group will rebalance the partitions to take over for the missing member

<ins>Brokers and Clusters:</ins>

- A single Kafka server is called a broker.
- The broker receives messages from producers, assigns offsets to them, and commits the messages to storage.
- The broker also services consumers, responding to fetch requests for partitions and responding with the messages that have been stored
- A single broker can easily handle thousands of partitions and millions of messages per second.
- Brokers are designed to operate as part of a cluster.
    - Within a cluser of brokers, one broker will also function as the cluster controller (elected automatically from other cluster members).
        - The controller is responsible for administrative operations, including assigning partitions to brokers and monitoring for broker failures.
    - A partition is owned by a singler broker in the cluster, and that broker is called the leader of the partition. 
        - A partition may be assigned to multiple brokers, which will result in the partition being replicated, and another broker can take over leadership if there is a broker failure. However, all consumers and producers operating on that partition must connect to the leader
    - Replication mechanisms are designed only to work within a single cluster, not between multiple clusters

<ins>Retention:</ins>

- Rentention is the durable storage of messages for some period of time. 
- Brokers are configured with default retention settings for topics, and individual topics can be configured with their own retention settings





[See a sketch of how publisher/subscriber systems work](https://excalidraw.com/#json=5152003063808000,TkiXjCU4Ng3qRkOmOa0o7Q)

[Resource](https://www.confluent.io/resources/kafka-the-definitive-guide/)